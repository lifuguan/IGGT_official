# <img src="./images/iggt_logo.png" alt="logo" width="30"/> IGGT: Instance-Grounded Geometry Transformer for Semantic 3D Reconstruction

This is the official repository for the paper:
> **IGGT: Instance-Grounded Geometry Transformer for Semantic 3D Reconstruction** 
>
> [Hao Li*](https://lifuguan.github.io/), [Zhengyu Zou*](), [Fangfu Liu*](https://scholar.google.com/citations?user=b-4FUVsAAAAJ&hl=zh-CN), [Xuanyang Zhang](https://scholar.google.com/citations?user=oPV20eMAAAAJ&hl=zh-CN), [Fangzhou Hong](https://scholar.google.com/citations?user=mhaiL5MAAAAJ&hl=zh-CN&oi=ao), [Yukang Cao](https://scholar.google.com/citations?user=1rIzYQgAAAAJ&hl=zh-CN&oi=ao), [Yushi Lan](https://scholar.google.com/citations?user=dTNZCUcAAAAJ&hl=zh-CN&oi=ao), [Manyuan Zhang](https://manyuan97.github.io/), [Gang Yu](https://www.skicyyu.org/), [Dingwen Zhang](https://teacher.nwpu.edu.cn/zdw2006yyy)<sup>†</sup>, and [Ziwei Liu](https://liuziwei7.github.io/)
>
> <sup>*</sup>Equal Contribution, <sup>†</sup>Project Leader, <img src="https://cdn.jsdelivr.net/gh/twitter/twemoji@14.0.2/assets/svg/2709.svg" alt="email" width="16"/>Corresponding author.
>
> ### <img src="https://raw.githubusercontent.com/simple-icons/simple-icons/develop/icons/arxiv.svg" alt="arXiv" width="20"/> [Paper](https://arxiv.org/abs/2510.22706) &nbsp; | &nbsp; <img src="https://raw.githubusercontent.com/simple-icons/simple-icons/develop/icons/internetarchive.svg" alt="Website" width="20"/> [Website](https://github.com/lifuguan) &nbsp; | &nbsp; <img src="https://huggingface.co/front/assets/huggingface_logo-noborder.svg" alt="HuggingFace" width="20"/> [Data](https://huggingface.co/datasets/lifuguan/InsScene-15K) 


<video autoplay loop muted playsinline style="max-width: 100%; border-radius: 15px; box-shadow: 0 10px 30px rgba(0, 0, 0, 0.2);">
    <source src="images/demo_video.mp4" type="video/mp4">
    Your browser does not support the video tag.
</video>

## 🔍 Overview
IGGT introduces a novel transformer-based architecture for semantic 3D reconstruction that grounds instance-level understanding in geometric representations. Our method achieves state-of-the-art performance on multiple benchmarks while maintaining computational efficiency.

**Key Features:**
- 🎯 Instance-grounded 3D feature learning
- 🏗️ Geometry-aware transformer architecture
- 📊 State-of-the-art performance on ScanNet and InsScene-15K
- ⚡ Efficient inference with multi-view consistency

## 📝 To-Do List

- [ ] Release project paper
- [ ] Release InsScene-15K dataset
- [ ] Release codebase
- [ ] Release pretrained models


## 📄 License
This project is released under the MIT License. See [LICENSE](LICENSE) for details.
